"""
Pipeline Visualization Routes - Tab 2

Provides API endpoints for:
- Pipeline results and context
- Audio file listing and serving
- Derivation visualization data

All data is read from JSON files generated by the main pipeline.
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

from fastapi import APIRouter, HTTPException
from fastapi.responses import FileResponse, JSONResponse

# -----------------------------------------------------------------------------
# Configuration
# -----------------------------------------------------------------------------

WEB_DIR = Path(__file__).parent.parent
PROJECT_ROOT = WEB_DIR.parent
GENERATION_RESULTS_DIR = PROJECT_ROOT / "generation_results"
MUSIC_DIR = PROJECT_ROOT / "music_generated"
PIPELINE_RESULTS_FILE = "pipeline_results.json"

# Files to skip when listing audio
AUDIO_FILE_SKIP_PREFIXES = ("generated_music", "POST_PROCESSOR")

# Filename pattern: world_theme_2026-01-09_20-33-17.wav
AUDIO_FILENAME_DATE_INDEX = 2
AUDIO_FILENAME_TIME_INDEX = 3

logger = logging.getLogger(__name__)
router = APIRouter()


# -----------------------------------------------------------------------------
# Data Loading Helpers
# -----------------------------------------------------------------------------

def _parse_timestamp(timestamp_str: str) -> Optional[str]:
    """Parse ISO timestamp to display format."""
    try:
        dt = datetime.fromisoformat(timestamp_str)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except (ValueError, TypeError):
        return timestamp_str


def _parse_audio_filename(filepath: Path) -> Dict[str, str]:
    """
    Extract date and time from audio filename.
    
    Expected format: world_theme_2026-01-09_20-33-17.wav
    
    Returns:
        Dict with 'date' and 'time' keys (empty strings if parsing fails)
    """
    date_str = ""
    time_str = ""
    
    try:
        parts = filepath.stem.split("_")
        if len(parts) > AUDIO_FILENAME_DATE_INDEX:
            date_str = parts[AUDIO_FILENAME_DATE_INDEX]
        if len(parts) > AUDIO_FILENAME_TIME_INDEX:
            time_str = parts[AUDIO_FILENAME_TIME_INDEX].replace("-", ":")
    except (IndexError, AttributeError) as e:
        logger.debug(f"Could not parse filename {filepath.name}: {e}")
    
    return {"date": date_str, "time": time_str}


def _format_file_size(size_bytes: int) -> str:
    """Format file size in human-readable format."""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    else:
        return f"{size_bytes / (1024 * 1024):.1f} MB"


def _load_json_file(filepath: Path) -> Optional[Dict[str, Any]]:
    """
    Safely load a JSON file.
    
    Returns:
        Parsed JSON data, or None if file doesn't exist or is invalid.
    """
    if not filepath.exists():
        return None
    
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON in {filepath}: {e}")
        return None
    except Exception as e:
        logger.exception(f"Error reading {filepath}")
        return None


# -----------------------------------------------------------------------------
# Pipeline Results
# -----------------------------------------------------------------------------

def load_pipeline_results() -> Dict[str, Any]:
    """
    Load the latest pipeline results from JSON file.
    
    Returns:
        Pipeline data dict, or dict with 'error' key if loading failed.
    """
    results_file = GENERATION_RESULTS_DIR / PIPELINE_RESULTS_FILE
    
    data = _load_json_file(results_file)
    
    if data is None:
        logger.info(f"No pipeline results found at {results_file}")
        return {"error": "No pipeline results found"}
    
    # Add formatted timestamp for display
    if "timestamp" in data:
        data["timestamp_display"] = _parse_timestamp(data["timestamp"])
    
    return data


def get_pipeline_context() -> Dict[str, Any]:
    """
    Get full pipeline context for template rendering.
    
    Returns:
        Dict containing pipeline data, audio files list, and count.
    """
    pipeline = load_pipeline_results()
    audio_files = get_audio_files()
    
    return {
        "pipeline": pipeline,
        "audio_files": audio_files,
        "audio_count": len(audio_files),
    }


# -----------------------------------------------------------------------------
# Audio Files
# -----------------------------------------------------------------------------

def get_audio_files() -> List[Dict[str, Any]]:
    """
    Get list of available audio files with metadata.
    
    Scans the music directory for .wav files, excluding placeholder
    and test files. Returns files sorted by name (newest first).
    
    Returns:
        List of audio file metadata dicts.
    """
    if not MUSIC_DIR.exists():
        logger.debug(f"Music directory does not exist: {MUSIC_DIR}")
        return []
    
    audio_files = []
    
    for filepath in sorted(MUSIC_DIR.glob("*.wav"), key=lambda p: p.name, reverse=True):
        # Skip placeholder and test files
        if filepath.name.startswith(AUDIO_FILE_SKIP_PREFIXES):
            continue
        
        # Parse date/time from filename
        parsed = _parse_audio_filename(filepath)
        
        # Get file size
        try:
            size_display = _format_file_size(filepath.stat().st_size)
        except OSError as e:
            logger.warning(f"Could not stat {filepath}: {e}")
            size_display = "Unknown"
        
        audio_files.append({
            "filename": filepath.name,
            "date": parsed["date"],
            "time": parsed["time"],
            "size": size_display,
            "url": f"/audio/{filepath.name}",
        })
    
    logger.debug(f"Found {len(audio_files)} audio files")
    return audio_files


# -----------------------------------------------------------------------------
# Derivation Visualization
# -----------------------------------------------------------------------------

def _load_news_for_derivation(pipeline_date: str) -> Dict[str, Any]:
    """
    Load news data for derivation visualization.
    
    Args:
        pipeline_date: Date string (YYYY-MM-DD) to find news file.
        
    Returns:
        News summary dict with article counts, sources, and sample headlines.
    """
    news_file = PROJECT_ROOT / f"news_data_{pipeline_date}.json"
    raw_news = _load_json_file(news_file)
    
    if raw_news is None:
        return {"error": "News file not found"}
    
    total_articles = 0
    sources: Set[str] = set()
    sample_headlines: List[Dict[str, str]] = []
    regions: List[str] = []
    
    for region_key, region_data in raw_news.items():
        if not isinstance(region_data, dict):
            continue
            
        articles = region_data.get("articles", [])
        if not isinstance(articles, list):
            continue
            
        total_articles += len(articles)
        regions.append(region_key)
        
        # Sample first 5 articles per region
        for article in articles[:5]:
            if not isinstance(article, dict):
                continue
                
            source_data = article.get("source", {})
            source_name = source_data.get("name", "Unknown") if isinstance(source_data, dict) else "Unknown"
            sources.add(source_name)
            
            if len(sample_headlines) < 10:
                title = article.get("title", "")
                sample_headlines.append({
                    "title": title[:80] if title else "",
                    "source": source_name,
                })
    
    return {
        "total_articles": total_articles,
        "regions": regions,
        "sources": sorted(sources)[:15],
        "sample_headlines": sample_headlines,
        "file": news_file.name,
    }


def _build_archetypes_data() -> Dict[str, Any]:
    """
    Build archetype profiles and descriptors from lib modules.
    
    Returns:
        Dict mapping archetype names to their full profile/descriptor data.
    """
    # Lazy import to avoid circular dependencies
    import sys
    if str(PROJECT_ROOT) not in sys.path:
        sys.path.insert(0, str(PROJECT_ROOT))
    
    from lib.archetypes import ARCHETYPES, ArchetypeName, COMPATIBILITY_MATRIX
    from lib.archetype_selector import ARCHETYPE_PROFILES
    
    archetypes_data = {}
    
    for name in ArchetypeName:
        profile = ARCHETYPE_PROFILES[name]
        descriptor = ARCHETYPES[name]
        
        archetypes_data[name.value] = {
            "name": name.value,
            "display_name": name.value.replace("_", " ").title(),
            "profile": {
                "valence_center": profile.valence_center,
                "valence_tolerance": profile.valence_tolerance,
                "tension_center": profile.tension_center,
                "tension_tolerance": profile.tension_tolerance,
                "hope_center": profile.hope_center,
                "hope_tolerance": profile.hope_tolerance,
                "preferred_energy": profile.preferred_energy,
            },
            "descriptor": {
                "genre": descriptor.genre,
                "instruments": descriptor.instruments,
                "mood_musical": descriptor.mood_musical,
                "mood_emotional": descriptor.mood_emotional,
                "tempo_bpm": descriptor.tempo_bpm,
                "tempo_value": descriptor.tempo_value,
                "technical": descriptor.technical,
            },
            "compatible_with": [a.value for a in COMPATIBILITY_MATRIX.get(name, [])],
        }
    
    return archetypes_data


def get_derivation_data() -> Dict[str, Any]:
    """
    Get enriched derivation data for pipeline visualization.
    
    Combines pipeline results with news data and archetype definitions
    to provide everything needed for the vis-network graph.
    
    Returns:
        Comprehensive derivation data for the frontend visualization.
    """
    pipeline = load_pipeline_results()
    
    if "error" in pipeline:
        return {"error": pipeline["error"]}
    
    # Get date for news file lookup
    pipeline_date = pipeline.get("date") or datetime.now().strftime("%Y-%m-%d")
    
    # Load news summary
    news_data = _load_news_for_derivation(pipeline_date)
    
    # Extract analysis metrics
    analysis = pipeline.get("analysis", {})
    input_metrics = {
        "valence": analysis.get("emotional_valence", 0),
        "tension": analysis.get("tension_level", 0),
        "hope": analysis.get("hope_factor", 0),
        "energy": analysis.get("energy_level", "medium"),
    }
    
    # Scoring weights (matches archetype_selector.py)
    scoring_weights = {
        "valence": 0.30,
        "tension": 0.25,
        "hope": 0.30,
        "energy": 0.15,
    }
    
    # Build archetype data
    try:
        archetypes_data = _build_archetypes_data()
    except ImportError as e:
        logger.error(f"Could not import archetype modules: {e}")
        archetypes_data = {}
    
    # Selection results
    selection = pipeline.get("selection", {})
    
    # Prompt components
    prompt_data = pipeline.get("prompt", {})
    prompt_components = prompt_data.get("components", {})
    
    return {
        "news": news_data,
        "summary": analysis.get("summary", ""),
        "input_metrics": input_metrics,
        "scoring_weights": scoring_weights,
        "archetypes": archetypes_data,
        "selection": {
            "primary": selection.get("primary"),
            "secondary": selection.get("secondary"),
            "blend_ratio": selection.get("blend_ratio"),
            "all_scores": selection.get("all_scores", []),
        },
        "prompt": {
            "final_prompt": prompt_data.get("prompt", ""),
            "components": {
                "genre": prompt_components.get("genre"),
                "instruments": prompt_components.get("base_instruments", []),
                "moods": prompt_components.get("base_moods", []),
                "tempo": prompt_components.get("tempo_final"),
                "intensity": prompt_components.get("intensity_level"),
                "instrument_variant": prompt_components.get("instrument_variant", 0),
                "texture_timbre": prompt_components.get("texture_timbre", []),
                "texture_movement": prompt_components.get("texture_movement", []),
                "texture_harmonic": prompt_components.get("texture_harmonic", []),
                "source_themes": prompt_components.get("source_themes", []),
            },
        },
        "themes": analysis.get("dominant_themes", []),
        "date": pipeline.get("date"),
    }


# -----------------------------------------------------------------------------
# API Routes
# -----------------------------------------------------------------------------

@router.get("/api/pipeline")
async def api_pipeline() -> JSONResponse:
    """API endpoint for pipeline results and audio files."""
    return JSONResponse(get_pipeline_context())


@router.get("/api/audio-files")
async def api_audio_files() -> JSONResponse:
    """API endpoint for audio files list (supports polling)."""
    files = get_audio_files()
    return JSONResponse({
        "files": files,
        "count": len(files),
        "timestamp": datetime.now().isoformat(),
    })


@router.get("/api/derivation")
async def api_derivation() -> JSONResponse:
    """API endpoint for derivation visualization data."""
    return JSONResponse(get_derivation_data())


@router.get("/audio/{filename:path}")
async def serve_audio(filename: str) -> FileResponse:
    """
    Serve audio file from the music directory.
    
    Args:
        filename: Name of the .wav file to serve.
        
    Returns:
        Audio file response with appropriate headers.
        
    Raises:
        HTTPException: If file not found or invalid format.
    """
    # Sanitize filename to prevent directory traversal
    if "/" in filename or "\\" in filename or ".." in filename:
        raise HTTPException(status_code=400, detail="Invalid filename")
    
    filepath = MUSIC_DIR / filename
    
    if not filepath.exists():
        raise HTTPException(status_code=404, detail="File not found")
    
    if filepath.suffix.lower() != ".wav":
        raise HTTPException(status_code=400, detail="Only .wav files are served")
    
    return FileResponse(
        filepath,
        media_type="audio/wav",
        filename=filename,
    )
